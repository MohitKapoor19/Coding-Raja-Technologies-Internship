{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c79104-0ea4-489b-908a-56e6180e2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "\n",
    "# Importing train_test_split to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing LogisticRegression for logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importing accuracy_score to evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6306859d-7968-4f3a-936d-4b48bd42266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset into a Pandas DataFrame\n",
    "credit_card_data = pd.read_csv('dataset/creditcard.csv')  # Reading the credit card dataset from a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0104803d-9ea3-49c8-8797-1a9da35822c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first five rows of the dataset\n",
    "credit_card_data.head()  # Using the head() function to preview the top five rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4e25e5-d581-4781-8946-ebccd6643b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the dataset\n",
    "credit_card_data.shape  # Using the shape attribute to get the number of rows and columns in the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4035d698-09d5-42b1-89a2-4746f5c40927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Displaying the dataset information\n",
    "credit_card_data.info()  # Using the info() method to get a concise summary of the DataFrame, including the data types and non-null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd753c35-1633-4442-ad77-8f19eae75143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in the dataset\n",
    "credit_card_data.isnull().sum()  # Using isnull() and sum() to count the number of missing values in each column of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c04f1b40-456b-4086-876b-9b1738cc3621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of legitimate transactions and fraudulent transactions\n",
    "credit_card_data['Class'].value_counts()  # Using value_counts() to count the occurrences of each class (0 for legit, 1 for fraudulent) in the 'Class' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb9afe99-f301-40af-9799-a80efac665ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset is highly unbalanced\n",
    "# 0 --> Normal Transaction\n",
    "# 1 --> Fraudulent Transaction\n",
    "\n",
    "# Separating the data for analysis\n",
    "legit = credit_card_data[credit_card_data.Class == 0]  # Creating a DataFrame with only legitimate transactions\n",
    "fraud = credit_card_data[credit_card_data.Class == 1]  # Creating a DataFrame with only fraudulent transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfc31931-99e3-4e4a-a863-de2b698945bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the legitimate transactions DataFrame\n",
    "legit.shape  # Using the shape attribute to get the number of rows and columns in the legit DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6465379a-6df9-438b-83a1-90fa0686fbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the fraudulent transactions DataFrame\n",
    "fraud.shape  # Using the shape attribute to get the number of rows and columns in the fraud DataFrame\n",
    "\n",
    "# Insight: Number of fraud transactions is much less than legit transactions\n",
    "# Fraud transactions are approximately 0.17% of legitimate transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7822ccb4-13ad-4182-ad94-a4da9f063e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics for the Amount of legitimate transactions\n",
    "legit.Amount.describe()  # Using the describe() method to get summary statistics (count, mean, std, min, 25%, 50%, 75%, max) for the 'Amount' column in the legit DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abf8a7e0-614c-43f5-ab0e-99fcbb82e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94838.202258</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>88.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0      94838.202258  0.008258 -0.006271  0.012171 -0.007860  0.005453   \n",
       "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
       "\n",
       "             V6        V7        V8        V9  ...       V20       V21  \\\n",
       "Class                                          ...                       \n",
       "0      0.002419  0.009637 -0.000987  0.004467  ... -0.000644 -0.001235   \n",
       "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0     -0.000024  0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   \n",
       "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
       "\n",
       "           Amount  \n",
       "Class              \n",
       "0       88.291022  \n",
       "1      122.211321  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the mean values for both types of transactions\n",
    "credit_card_data.groupby('Class').mean()  # Using groupby() to group the data by 'Class' and then calculating the mean for each group\n",
    "\n",
    "# Insight: There is a significant difference between the mean of normal transactions and fraudulent transactions \n",
    "# for every PCA component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4375a719-a2d1-482e-9e33-e46900a09b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under-Sampling\n",
    "# Build a sample dataset containing a similar distribution of normal transactions and fraudulent transactions\n",
    "# Number of fraudulent transactions --> 492\n",
    "\n",
    "# Creating a sample of legitimate transactions with the same number of entries as fraudulent transactions\n",
    "legit_sample = legit.sample(n=492)  # Using sample() to randomly select 492 entries from the legitimate transactions DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efcd734d-3838-4f28-a35e-f5a1312ddff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the two DataFrames\n",
    "new_dataset = pd.concat([legit_sample, fraud], axis=0)  # Using concat() to combine the sampled legitimate transactions and all fraudulent transactions along the rows (axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0582687-9119-49ba-a787-935e9c059b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212630</th>\n",
       "      <td>138934.0</td>\n",
       "      <td>0.057882</td>\n",
       "      <td>0.864656</td>\n",
       "      <td>0.231735</td>\n",
       "      <td>-0.620513</td>\n",
       "      <td>0.473081</td>\n",
       "      <td>-1.041149</td>\n",
       "      <td>1.006732</td>\n",
       "      <td>-0.195905</td>\n",
       "      <td>-0.028062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271327</td>\n",
       "      <td>-0.601652</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>-0.118321</td>\n",
       "      <td>-0.471348</td>\n",
       "      <td>0.147594</td>\n",
       "      <td>0.247038</td>\n",
       "      <td>0.095723</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125031</th>\n",
       "      <td>77514.0</td>\n",
       "      <td>1.262596</td>\n",
       "      <td>-0.161896</td>\n",
       "      <td>0.462786</td>\n",
       "      <td>-0.245087</td>\n",
       "      <td>-0.668115</td>\n",
       "      <td>-0.537432</td>\n",
       "      <td>-0.391293</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.321630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116252</td>\n",
       "      <td>-0.409580</td>\n",
       "      <td>0.057185</td>\n",
       "      <td>0.036314</td>\n",
       "      <td>0.094702</td>\n",
       "      <td>0.910872</td>\n",
       "      <td>-0.082065</td>\n",
       "      <td>-0.006358</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57682</th>\n",
       "      <td>48012.0</td>\n",
       "      <td>1.142160</td>\n",
       "      <td>-0.018281</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>1.222289</td>\n",
       "      <td>-0.132475</td>\n",
       "      <td>0.278956</td>\n",
       "      <td>-0.195308</td>\n",
       "      <td>0.282078</td>\n",
       "      <td>0.397965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097492</td>\n",
       "      <td>-0.190981</td>\n",
       "      <td>-0.088247</td>\n",
       "      <td>-0.349663</td>\n",
       "      <td>0.599787</td>\n",
       "      <td>-0.302344</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>-0.002246</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16883</th>\n",
       "      <td>28263.0</td>\n",
       "      <td>1.141315</td>\n",
       "      <td>-0.951765</td>\n",
       "      <td>-0.074941</td>\n",
       "      <td>-0.790461</td>\n",
       "      <td>-0.732216</td>\n",
       "      <td>-0.175276</td>\n",
       "      <td>-0.472864</td>\n",
       "      <td>0.048217</td>\n",
       "      <td>-0.991942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327187</td>\n",
       "      <td>0.569871</td>\n",
       "      <td>-0.225374</td>\n",
       "      <td>-0.283458</td>\n",
       "      <td>0.494687</td>\n",
       "      <td>-0.093017</td>\n",
       "      <td>-0.022259</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>125.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26709</th>\n",
       "      <td>34216.0</td>\n",
       "      <td>1.189451</td>\n",
       "      <td>0.275206</td>\n",
       "      <td>0.402907</td>\n",
       "      <td>0.725453</td>\n",
       "      <td>-0.391748</td>\n",
       "      <td>-0.802063</td>\n",
       "      <td>-0.020295</td>\n",
       "      <td>-0.055590</td>\n",
       "      <td>0.087825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244641</td>\n",
       "      <td>-0.699701</td>\n",
       "      <td>0.205390</td>\n",
       "      <td>0.345343</td>\n",
       "      <td>0.081570</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "212630  138934.0  0.057882  0.864656  0.231735 -0.620513  0.473081 -1.041149   \n",
       "125031   77514.0  1.262596 -0.161896  0.462786 -0.245087 -0.668115 -0.537432   \n",
       "57682    48012.0  1.142160 -0.018281  0.240965  1.222289 -0.132475  0.278956   \n",
       "16883    28263.0  1.141315 -0.951765 -0.074941 -0.790461 -0.732216 -0.175276   \n",
       "26709    34216.0  1.189451  0.275206  0.402907  0.725453 -0.391748 -0.802063   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "212630  1.006732 -0.195905 -0.028062  ... -0.271327 -0.601652  0.049907   \n",
       "125031 -0.391293  0.064000  0.321630  ... -0.116252 -0.409580  0.057185   \n",
       "57682  -0.195308  0.282078  0.397965  ... -0.097492 -0.190981 -0.088247   \n",
       "16883  -0.472864  0.048217 -0.991942  ...  0.327187  0.569871 -0.225374   \n",
       "26709  -0.020295 -0.055590  0.087825  ... -0.244641 -0.699701  0.205390   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "212630 -0.118321 -0.471348  0.147594  0.247038  0.095723    2.58      0  \n",
       "125031  0.036314  0.094702  0.910872 -0.082065 -0.006358    2.26      0  \n",
       "57682  -0.349663  0.599787 -0.302344  0.020648 -0.002246    9.00      0  \n",
       "16883  -0.283458  0.494687 -0.093017 -0.022259  0.011375  125.75      0  \n",
       "26709   0.345343  0.081570  0.105707 -0.009713  0.029592    1.98      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first five rows of the new dataset\n",
    "new_dataset.head()  # Using the head() function to preview the top five rows of the concatenated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97acede9-0c0a-4e83-ba4f-7369f5fb3212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    492\n",
       "1    492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of the 'Class' column in the new dataset\n",
    "new_dataset['Class'].value_counts()  # Using value_counts() to count the occurrences of each class (0 for legit, 1 for fraudulent) in the 'Class' column of the new dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56ad5857-021e-4498-8666-629db89fe924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96060.558943</td>\n",
       "      <td>0.111330</td>\n",
       "      <td>0.072713</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>0.023651</td>\n",
       "      <td>-0.037147</td>\n",
       "      <td>-0.057567</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.059066</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009810</td>\n",
       "      <td>-0.013956</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>-0.023643</td>\n",
       "      <td>-0.049097</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>82.017459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0      96060.558943  0.111330  0.072713 -0.001155  0.023651 -0.037147   \n",
       "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
       "\n",
       "             V6        V7        V8        V9  ...       V20       V21  \\\n",
       "Class                                          ...                       \n",
       "0     -0.057567  0.062000  0.059066  0.001833  ... -0.009810 -0.013956   \n",
       "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0      0.018107 -0.023643 -0.049097  0.007916 -0.000729  0.000529  0.011109   \n",
       "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
       "\n",
       "           Amount  \n",
       "Class              \n",
       "0       82.017459  \n",
       "1      122.211321  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the mean values for both types of transactions in the new dataset\n",
    "new_dataset.groupby('Class').mean()  # Using groupby() to group the data by 'Class' and then calculating the mean for each group\n",
    "\n",
    "# Insight: Despite the under-sampling, the dataset remains highly unbalanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3054b166-092f-4668-b2af-5be0a93e1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 30) (787, 30) (197, 30)\n",
      "Accuracy on Training data (Random Forest): 1.0\n",
      "Accuracy score on Test Data (Random Forest): 0.9187817258883249\n",
      "Accuracy on Training data (SVM): 0.9567979669631512\n",
      "Accuracy score on Test Data (SVM): 0.9187817258883249\n"
     ]
    }
   ],
   "source": [
    "# Now we will split the data into Features and Targets\n",
    "# Then we will feed this data to our machine learning model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = new_dataset.drop(columns='Class', axis=1)\n",
    "Y = new_dataset['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(X.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "# Create and fit a pipeline with scaling and Random Forest\n",
    "pipeline_rf = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=2))\n",
    "pipeline_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Accuracy on training data for Random Forest\n",
    "X_train_prediction_rf = pipeline_rf.predict(X_train)\n",
    "training_data_accuracy_rf = accuracy_score(Y_train, X_train_prediction_rf)\n",
    "print('Accuracy on Training data (Random Forest):', training_data_accuracy_rf)\n",
    "\n",
    "# Accuracy on test data for Random Forest\n",
    "X_test_prediction_rf = pipeline_rf.predict(X_test)\n",
    "test_data_accuracy_rf = accuracy_score(Y_test, X_test_prediction_rf)\n",
    "print('Accuracy score on Test Data (Random Forest):', test_data_accuracy_rf)\n",
    "\n",
    "# Create and fit a pipeline with scaling and Support Vector Machine\n",
    "pipeline_svm = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=2))\n",
    "pipeline_svm.fit(X_train, Y_train)\n",
    "\n",
    "# Accuracy on training data for SVM\n",
    "X_train_prediction_svm = pipeline_svm.predict(X_train)\n",
    "training_data_accuracy_svm = accuracy_score(Y_train, X_train_prediction_svm)\n",
    "print('Accuracy on Training data (SVM):', training_data_accuracy_svm)\n",
    "\n",
    "# Accuracy on test data for SVM\n",
    "X_test_prediction_svm = pipeline_svm.predict(X_test)\n",
    "test_data_accuracy_svm = accuracy_score(Y_test, X_test_prediction_svm)\n",
    "print('Accuracy score on Test Data (SVM):', test_data_accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a345433-3eef-4258-b1c7-3a95e07f3bad",
   "metadata": {},
   "source": [
    "# Analysis Report\r\n",
    "\r\n",
    "## Dataset Shapes\r\n",
    "- The entire dataset has **984 samples** and **30 features**.\r\n",
    "- The training set has **787 samples** and **30 features**.\r\n",
    "- The test set has **197 samples** and **30 features**.\r\n",
    "\r\n",
    "## Accuracy\r\n",
    "- The logistic regression model achieved **95.30% accuracy** on the training data.\r\n",
    "- It achieved **92.39% accuracy** on the test data.\r\n",
    "\r\n",
    "## Insights\r\n",
    "\r\n",
    "### 1. High Training Accuracy\r\n",
    "- The training accuracy of **95.30%** indicates that the model is performing very well on the data it was trained on, effectively learning the patterns in the training data.\r\n",
    "\r\n",
    "### 2. High Test Accuracy\r\n",
    "- The test accuracy of **92.39%** suggests that the model is also performing well on unseen data, indicating good generalization capabilities.\r\n",
    "\r\n",
    "### 3. Generalization Performance\r\n",
    "- The slight drop in accuracy from training (**95.30%**) to test (**92.39%**) is expected and typical. It indicates that the model is not overfitting significantly, as there is no drastic drop in performance. A small drop suggests that the model has generalized well from the training data to the test data.\r\n",
    "\r\n",
    "### 4. Model Evaluation\r\n",
    "- The high accuracy on both training and test datasets indicates that the preprocessing steps (such as scaling) and the logistic regression model are well-suited for this classification task. However, it is important to note that accuracy is just one metric. For a more comprehensive understanding, other metrics like precision, recall, F1-score, and the confusion matrix should also be considered.\r\n",
    "accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1d0ca60-de37-4670-85b3-cee630b191cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training Data:\n",
      "Precision on Training Data: 0.9545421748183011\n",
      "Recall on Training Data: 0.9529860228716646\n",
      "F1-Score on Training Data: 0.9529475842725275\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       393\n",
      "           1       0.98      0.92      0.95       394\n",
      "\n",
      "    accuracy                           0.95       787\n",
      "   macro avg       0.95      0.95      0.95       787\n",
      "weighted avg       0.95      0.95      0.95       787\n",
      "\n",
      "\n",
      "Evaluation on Test Data:\n",
      "Precision on Test Data: 0.925983364399225\n",
      "Recall on Test Data: 0.9238578680203046\n",
      "F1-Score on Test Data: 0.9237478161583647\n",
      "Classification Report for Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        99\n",
      "           1       0.96      0.89      0.92        98\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.93      0.92      0.92       197\n",
      "weighted avg       0.93      0.92      0.92       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Evaluation on training data\n",
    "print(\"Evaluation on Training Data:\")\n",
    "precision_train = precision_score(Y_train, X_train_prediction, average='weighted')\n",
    "recall_train = recall_score(Y_train, X_train_prediction, average='weighted')\n",
    "f1_train = f1_score(Y_train, X_train_prediction, average='weighted')\n",
    "\n",
    "print('Precision on Training Data:', precision_train)\n",
    "print('Recall on Training Data:', recall_train)\n",
    "print('F1-Score on Training Data:', f1_train)\n",
    "print('Classification Report for Training Data:\\n', classification_report(Y_train, X_train_prediction))\n",
    "\n",
    "# Evaluation on test data\n",
    "print(\"\\nEvaluation on Test Data:\")\n",
    "precision_test = precision_score(Y_test, X_test_prediction, average='weighted')\n",
    "recall_test = recall_score(Y_test, X_test_prediction, average='weighted')\n",
    "f1_test = f1_score(Y_test, X_test_prediction, average='weighted')\n",
    "\n",
    "print('Precision on Test Data:', precision_test)\n",
    "print('Recall on Test Data:', recall_test)\n",
    "print('F1-Score on Test Data:', f1_test)\n",
    "print('Classification Report for Test Data:\\n', classification_report(Y_test, X_test_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48007d-2d18-4066-a1aa-271c950e50ff",
   "metadata": {},
   "source": [
    "# Insights from the Model Evaluation\r\n",
    "\r\n",
    "## 1. Training Data Evaluation\r\n",
    "- **Precision:** 95.45%\r\n",
    "- **Recall:** 95.30%\r\n",
    "- **F1-Score:** 95.29%\r\n",
    "- **Classification Report:**\r\n",
    "  - **Class 0:** High precision (93%) and recall (98%) with an F1-score of 95%.\r\n",
    "  - **Class 1:** High precision (98%) and recall (92%) with an F1-score of 95%.\r\n",
    "  - **Overall accuracy:** 95%\r\n",
    "\r\n",
    "## 2. Test Data Evaluation\r\n",
    "- **Precision:** 92.60%\r\n",
    "- **Recall:** 92.39%\r\n",
    "- **F1-Score:** 92.37%\r\n",
    "- **Classification Report:**\r\n",
    "  - **Class 0:** High precision (90%) and recall (96%) with an F1-score of 93%.\r\n",
    "  - **Class 1:** High precision (96%) and recall (89%) with an F1-score of 92%.\r\n",
    "  - **Overall accuracy:** 92%\r\n",
    "\r\n",
    "## Detailed Insights\r\n",
    "\r\n",
    "### 1. Model Performance\r\n",
    "- The model performs well on both the training and test datasets, indicating good generalization.\r\n",
    "- Training accuracy is slightly higher than test accuracy, which is expected but should not be significantly different to avoid overfitting.\r\n",
    "\r\n",
    "### 2. Class-wise Performance\r\n",
    "- **For Class 0:**\r\n",
    "  - High recall (98% on training, 96% on test) indicates that most of the actual Class 0 samples are correctly identified.\r\n",
    "  - High precision (93% on training, 90% on test) indicates that most of the predicted Class 0 samples are actually Class 0.\r\n",
    "- **For Class 1:**\r\n",
    "  - High precision (98% on training, 96% on test) indicates that most of the predicted Class 1 samples are actually Class 1.\r\n",
    "  - Slightly lower recall (92% on training, 89% on test) compared to precision, but still good.\r\n",
    "\r\n",
    "### 3. Overall Metrics\r\n",
    "- Both macro and weighted averages of precision, recall, and F1-score are high, indicating balanced performance across both classes.\r\n",
    "- The small drop in test performance metrics compared to training metrics suggests that the model is not overfitting and has good generalization capability.\r\n",
    "d generalization capability.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bdce70dd-bfa0-4c39-a713-747b02779259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training data (Random Forest): 1.0\n",
      "Accuracy score on Test Data (Random Forest): 0.9187817258883249\n",
      "Evaluation on Training Data (Random Forest):\n",
      "Precision on Training Data (Random Forest): 1.0\n",
      "Recall on Training Data (Random Forest): 1.0\n",
      "F1-Score on Training Data (Random Forest): 1.0\n",
      "Classification Report for Training Data (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       393\n",
      "           1       1.00      1.00      1.00       394\n",
      "\n",
      "    accuracy                           1.00       787\n",
      "   macro avg       1.00      1.00      1.00       787\n",
      "weighted avg       1.00      1.00      1.00       787\n",
      "\n",
      "\n",
      "Evaluation on Test Data (Random Forest):\n",
      "Precision on Test Data (Random Forest): 0.9215311710970898\n",
      "Recall on Test Data (Random Forest): 0.9187817258883249\n",
      "F1-Score on Test Data (Random Forest): 0.9186307313692161\n",
      "Classification Report for Test Data (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92        99\n",
      "           1       0.96      0.88      0.91        98\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.92      0.92      0.92       197\n",
      "weighted avg       0.92      0.92      0.92       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Random Forest predictions on training and test data\n",
    "X_train_prediction_rf = pipeline_rf.predict(X_train)\n",
    "X_test_prediction_rf = pipeline_rf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "training_data_accuracy_rf = accuracy_score(Y_train, X_train_prediction_rf)\n",
    "test_data_accuracy_rf = accuracy_score(Y_test, X_test_prediction_rf)\n",
    "\n",
    "print('Accuracy on Training data (Random Forest):', training_data_accuracy_rf)\n",
    "print('Accuracy score on Test Data (Random Forest):', test_data_accuracy_rf)\n",
    "\n",
    "# Evaluation on training data\n",
    "print(\"Evaluation on Training Data (Random Forest):\")\n",
    "precision_train_rf = precision_score(Y_train, X_train_prediction_rf, average='weighted')\n",
    "recall_train_rf = recall_score(Y_train, X_train_prediction_rf, average='weighted')\n",
    "f1_train_rf = f1_score(Y_train, X_train_prediction_rf, average='weighted')\n",
    "\n",
    "print('Precision on Training Data (Random Forest):', precision_train_rf)\n",
    "print('Recall on Training Data (Random Forest):', recall_train_rf)\n",
    "print('F1-Score on Training Data (Random Forest):', f1_train_rf)\n",
    "print('Classification Report for Training Data (Random Forest):\\n', classification_report(Y_train, X_train_prediction_rf))\n",
    "\n",
    "# Evaluation on test data\n",
    "print(\"\\nEvaluation on Test Data (Random Forest):\")\n",
    "precision_test_rf = precision_score(Y_test, X_test_prediction_rf, average='weighted')\n",
    "recall_test_rf = recall_score(Y_test, X_test_prediction_rf, average='weighted')\n",
    "f1_test_rf = f1_score(Y_test, X_test_prediction_rf, average='weighted')\n",
    "\n",
    "print('Precision on Test Data (Random Forest):', precision_test_rf)\n",
    "print('Recall on Test Data (Random Forest):', recall_test_rf)\n",
    "print('F1-Score on Test Data (Random Forest):', f1_test_rf)\n",
    "print('Classification Report for Test Data (Random Forest):\\n', classification_report(Y_test, X_test_prediction_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f2912-33c8-4e1e-baff-1d9717a5a1de",
   "metadata": {},
   "source": [
    "# Analysis of Random Forest Model Performance\r\n",
    "\r\n",
    "## Training Data Performance\r\n",
    "- **Accuracy on Training Data:** 1.0\r\n",
    "  - The model has perfectly classified all training samples, achieving 100% accuracy.\r\n",
    "- **Precision on Training Data:** 1.0\r\n",
    "  - Precision is the ratio of true positive predictions to the total predicted positives. A precision of 1.0 means that every positive prediction made by the model was correct.\r\n",
    "- **Recall on Training Data:** 1.0\r\n",
    "  - Recall is the ratio of true positive predictions to the total actual positives. A recall of 1.0 means that the model correctly identified all positive samples.\r\n",
    "- **F1-Score on Training Data:** 1.0\r\n",
    "  - The F1-score, which is the harmonic mean of precision and recall, is 1.0, indicating perfect performance.\r\n",
    "\r\n",
    "### Classification Report for Training Data\r\n",
    "- **Class 0 and Class 1:**\r\n",
    "  - Precision, recall, and F1-score for both classes are 1.0.\r\n",
    "  - The model perfectly distinguishes between the two classes with no errors.\r\n",
    "\r\n",
    "## Test Data Performance\r\n",
    "- **Accuracy on Test Data:** 0.9187817258883249 (~91.88%)\r\n",
    "  - The model correctly classified approximately 91.88% of the test samples.\r\n",
    "- **Precision on Test Data:** 0.9215311710970898 (~92.15%)\r\n",
    "  - The precision indicates that about 92.15% of the positive predictions were correct.\r\n",
    "- **Recall on Test Data:** 0.9187817258883249 (~91.88%)\r\n",
    "  - The recall shows that the model correctly identified about 91.88% of the actual positives.\r\n",
    "- **F1-Score on Test Data:** 0.9186307313692161 (~91.86%)\r\n",
    "  - The F1-score balances the precision and recall, indicating overall strong performance.\r\n",
    "\r\n",
    "### Classification Report for Test Data\r\n",
    "- **Class 0:**\r\n",
    "  - Precision: 0.89\r\n",
    "  - Recall: 0.96\r\n",
    "  - F1-Score: 0.92\r\n",
    "  - The model performs well on Class 0, with high recall indicating most actual positives are identified.\r\n",
    "- **Class 1:**\r\n",
    "  - Precision: 0.96\r\n",
    "  - Recall: 0.88\r\n",
    "  - F1-Score: 0.91\r\n",
    "  - The model also performs well on Class 1, with high precision indicating most predictedorrect.\r\n",
    "\r\n",
    "## Insights and Observations\r\n",
    "- **Overfitting:**\r\n",
    "  - The model's perfect performance on the training data (accuracy, precision, recall, and F1-score all being 1.0) suggests overfitting. Overfitting occurs when the model learns the training data too well, including noise and outliers, resulting in excellent performance on the training set but not necessarily on unseen data.\r\n",
    "- **Generalization:**\r\n",
    "  - The test data performance, while still strong, shows a drop from the training data. The accuracy is approximately 91.88%, which is good but indicates the model does not generalize as perfectly as it performs on the training set. This gap between training and test performance is a sign of overfitting.\r\n",
    "- **Class Performance:**\r\n",
    "  - The model performs slightly better on Class 1 in terms of precision and slightly better on Class 0 in terms of recall. This could indicate a slight bias towards predicting Class 0 correctly.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0b2b6936-5fba-414e-bafd-fb61aae12b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Training Data (SVM):\n",
      "Precision on Training Data (SVM): 0.957983703306819\n",
      "Recall on Training Data (SVM): 0.9567979669631512\n",
      "F1-Score on Training Data (SVM): 0.9567714458639828\n",
      "Classification Report for Training Data (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       393\n",
      "           1       0.98      0.93      0.96       394\n",
      "\n",
      "    accuracy                           0.96       787\n",
      "   macro avg       0.96      0.96      0.96       787\n",
      "weighted avg       0.96      0.96      0.96       787\n",
      "\n",
      "\n",
      "Evaluation on Test Data (SVM):\n",
      "Precision on Test Data (SVM): 0.9203171800611659\n",
      "Recall on Test Data (SVM): 0.9187817258883249\n",
      "F1-Score on Test Data (SVM): 0.9186937184705568\n",
      "Classification Report for Test Data (SVM):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        99\n",
      "           1       0.95      0.89      0.92        98\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.92      0.92      0.92       197\n",
      "weighted avg       0.92      0.92      0.92       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM predictions on training and test data\n",
    "X_train_prediction_svm = pipeline_svm.predict(X_train)\n",
    "X_test_prediction_svm = pipeline_svm.predict(X_test)\n",
    "\n",
    "# Evaluation on training data\n",
    "print(\"Evaluation on Training Data (SVM):\")\n",
    "precision_train_svm = precision_score(Y_train, X_train_prediction_svm, average='weighted')\n",
    "recall_train_svm = recall_score(Y_train, X_train_prediction_svm, average='weighted')\n",
    "f1_train_svm = f1_score(Y_train, X_train_prediction_svm, average='weighted')\n",
    "\n",
    "print('Precision on Training Data (SVM):', precision_train_svm)\n",
    "print('Recall on Training Data (SVM):', recall_train_svm)\n",
    "print('F1-Score on Training Data (SVM):', f1_train_svm)\n",
    "print('Classification Report for Training Data (SVM):\\n', classification_report(Y_train, X_train_prediction_svm))\n",
    "\n",
    "# Evaluation on test data\n",
    "print(\"\\nEvaluation on Test Data (SVM):\")\n",
    "precision_test_svm = precision_score(Y_test, X_test_prediction_svm, average='weighted')\n",
    "recall_test_svm = recall_score(Y_test, X_test_prediction_svm, average='weighted')\n",
    "f1_test_svm = f1_score(Y_test, X_test_prediction_svm, average='weighted')\n",
    "\n",
    "print('Precision on Test Data (SVM):', precision_test_svm)\n",
    "print('Recall on Test Data (SVM):', recall_test_svm)\n",
    "print('F1-Score on Test Data (SVM):', f1_test_svm)\n",
    "print('Classification Report for Test Data (SVM):\\n', classification_report(Y_test, X_test_prediction_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534b2f-9b9a-42d8-be27-e45ba8651b55",
   "metadata": {},
   "source": [
    "# Analysis of SVM Model Performance\r\n",
    "\r\n",
    "## Training Data Performance\r\n",
    "- **Accuracy on Training Data:** 0.96\r\n",
    "  - The model has classified 96% of the training samples correctly.\r\n",
    "- **Precision on Training Data:** 0.957983703306819 (~95.80%)\r\n",
    "  - Precision is the ratio of true positive predictions to the total predicted positives. A precision of ~95.80% indicates that the majority of positive predictions made by the model were correct.\r\n",
    "- **Recall on Training Data:** 0.9567979669631512 (~95.68%)\r\n",
    "  - Recall is the ratio of true positive predictions to the total actual positives. A recall of ~95.68% indicates that the model correctly identified most of the positive samples.\r\n",
    "- **F1-Score on Training Data:** 0.9567714458639828 (~95.68%)\r\n",
    "  - The F1-score, which is the harmonic mean of precision and recall, is ~95.68%, indicating a balanced performance between precision and recall.\r\n",
    "\r\n",
    "### Classification Report for Training Data\r\n",
    "- **Class 0:**\r\n",
    "  - Precision: 0.93\r\n",
    "  - Recall: 0.98\r\n",
    "  - F1-Score: 0.96\r\n",
    "  - The model performs well on Class 0 with high recall.\r\n",
    "- **Class 1:**\r\n",
    "  - Precision: 0.98\r\n",
    "  - Recall: 0.93\r\n",
    "  - F1-Score: 0.96\r\n",
    "  - The model performs well on Class 1 with high precision.\r\n",
    "\r\n",
    "## Test Data Performance\r\n",
    "- **Accuracy on Test Data:** 0.9187817258883249 (~91.88%)\r\n",
    "  - The model correctly classified approximately 91.88% of the test samples.\r\n",
    "- **Precision on Test Data:** 0.9203171800611659 (~92.03%)\r\n",
    "  - Precision indicates that about 92.03% of the positive predictions were correct.\r\n",
    "- **Recall on Test Data:** 0.9187817258883249 (~91.88%)\r\n",
    "  - Recall shows that the model correctly identified about 91.88% of the actual positives.\r\n",
    "- **F1-Score on Test Data:** 0.9186937184705568 (~91.87%)\r\n",
    "  - The F1-score balances the precision and recall, indicating overall strong performance.\r\n",
    "\r\n",
    "### Classification Report for Test Data\r\n",
    "- **Class 0:**\r\n",
    "  - Precision: 0.90\r\n",
    "  - Recall: 0.95\r\n",
    "  - F1-Score: 0.92\r\n",
    "  - The model performs well on Class 0, with high recall indicating most actual positives are identified.\r\n",
    "- **Class 1:**\r\n",
    "  - Precision: 0.95\r\n",
    "  - Recall: 0.89\r\n",
    "  - F1-Score: 0.92\r\n",
    "  - The model also performs well on Class 1, with high precision indicating most predicted positives are correct.\r\n",
    "\r\n",
    "## Insights and Observations\r\n",
    "- **Good Generalization:**\r\n",
    "  - The SVM model has a high accuracy of 96% on the training data and approximately 91.88% on the test data. This indicates that the model generalizes well to unseen data and does not overfit as severely as the Random Forest model.\r\n",
    "- **Balanced Performance:**\r\n",
    "  - The precision, recall, and F1-scores are consistently high for both the training and test datasets, indicating that the model maintains a balanced performance across different metrics.\r\n",
    "- **Class Performance:**\r\n",
    "  - The model performs slightly better on Class 1 in terms of precision and slightly better on Class 0 in terms of recall on the test data. This could indicate aslight bias towards predicting Class 0 correctly.\r\n",
    "\r\n",
    "## Comparison with Random Forest\r\n",
    "- **Training Performance:**\r\n",
    "  - Random Forest shows perfect performance on the training data (indicating overfitting), while SVM has high but not perfect accuracy, suggesting better generalization.\r\n",
    "- **Test Performance:**\r\n",
    "  - Both models have similar test accuracy (~91.88%). However, SVM shows a more balanced performance between training and test data, indicating better generalization compared to Random Forest.\r\n",
    "- **Precision and Recall:**\r\n",
    "  - SVM maintains high precision and recall on both training and test data, while Random Forest shows a slight drop in test performance compared to its training performance.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5afae-60e5-42cb-9087-9093013fe6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
